# Source: fault-management-helm/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fault-management-config
  namespace: amcop-system
data:
  application.properties: |
    server.port=9797
    sdnr.client=http://sdnr.amcop-system.svc.cluster.local:8181/
    sdnr.client.username=admin
    sdnr.client.password=Kp8bJ4SXszM0WXlhak3eHlcse2gAw84vaoGGmJvUy2U
    sdnr.persist.get_all_nodes=120000

    #spring.data.elasticsearch.repositories.enabled=true
    elasticsearch.client.uris=http://sdnrdb.amcop-system.svc.cluster.local:9200/faultcurrent-v7/_search
    ## Testing only
    spring.datasource.hikari.connectionTimeout=20000
    spring.datasource.hikari.maximumPoolSize=5

    ## PostgreSQL
    spring.datasource.url=jdbc:postgresql://postgresql.amcop-system.svc.cluster.local:5432/holmes
    #spring.datasource.url=jdbc:postgresql://postgresql.amcop-system.svc.cluster.local:5431/holmes
    spring.datasource.username=holmes
    spring.datasource.password=holmespwd

    # create and drop table, good for testing, production set to none or comment it
    #spring.jpa.hibernate.ddl-auto=create-drop

    ##Rule Adapter Host
    ruleadapter.client=http://rule-adapter-helm.amcop-system.svc.cluster.local:8080/
    keycloak.server.url=http://keycloak-service.amcop-system.svc.cluster.local:8080/
    keycloak.realm.name=master
    keycloak.realm.client_id=admin-cli
    keycloak.realm.cli.username=admin
    keycloak.realm.cli.password=admin
    keycloak.realm.cli.grant_type=password
---
# Source: fault-management-helm/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: fault-management-helm
  namespace: amcop-system
  labels:
    app.kubernetes.io/name: fault-management-helm
    app.kubernetes.io/instance: fault-management-helm
spec:
  type: ClusterIP
  ports:
    - port: 9797
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: fault-management-helm
    app.kubernetes.io/instance: fault-management-helm
---
# Source: fault-management-helm/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fault-management-helm
  namespace: amcop-system
  labels:
    app.kubernetes.io/name: fault-management-helm
    app.kubernetes.io/instance: fault-management-helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: fault-management-helm
      app.kubernetes.io/instance: fault-management-helm
  template:
    metadata:
      labels:
        app.kubernetes.io/name: fault-management-helm
        app.kubernetes.io/instance: fault-management-helm
    spec:
      initContainers:
        - name: wait-for-svc-before-starup
          image: busybox
          command: ["sh", "-c", "until timeout 1 nc -z postgresql.amcop-system.svc.cluster.local 5432 > /dev/null; do echo Waiting for master.; sleep 1; done"]
      volumes:
        - name: fault-management-config
          configMap:
            name: fault-management-config
      containers:
        - name: fault-management-helm
          image: "amcop/faultprovider:v3.5.01122024"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - mountPath: /var/opt/faultprovider/config
              name: fault-management-config
          ports:
            - name: http
              containerPort: 9797

################################[ HOLMES_ENGINE_MANAGEMENT ]################################
---
# Source: holmes-engine-managment/charts/postgress/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secrets
  namespace: amcop-system
data:
  postgresql-password: "aG9sbWVzcHdk"
  repmgr-password: "aG9sbWVzcHdk"
---
# Source: holmes-engine-managment/charts/postgress/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: pgpool-secrets
  namespace: amcop-system
data:
  admin-password: "SFRzaVZxYjdSZQ=="
---
# Source: holmes-engine-managment/charts/postgress/templates/configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-configmap
  namespace: amcop-system
data:
  pre-stop.sh: |-
    #!/bin/bash
    set -o errexit
    set -o pipefail
    set -o nounset

    # Debug section
    exec 3>&1
    exec 4>&2

    # Load Libraries
    . /opt/bitnami/scripts/liblog.sh
    . /opt/bitnami/scripts/libpostgresql.sh
    . /opt/bitnami/scripts/librepmgr.sh

    # Auxiliary functions
    is_new_primary_ready() {
        return_value=1
        currenty_primary_node="$(repmgr_get_primary_node)"
        currenty_primary_host="$(echo $currenty_primary_node | awk '{print $1}')"

        info "$currenty_primary_host != $REPMGR_NODE_NETWORK_NAME"
        if [[ $(echo $currenty_primary_node | wc -w) -eq 2 ]] && [[ "$currenty_primary_host" != "$REPMGR_NODE_NETWORK_NAME" ]]; then
            info "New primary detected, leaving the cluster..."
            return_value=0
        else
            info "Waiting for a new primary to be available..."
        fi
        return $return_value
    }

    export MODULE="pre-stop-hook"

    if [[ "${BITNAMI_DEBUG}" == "true" ]]; then
        info "Bash debug is on"
    else
        info "Bash debug is off"
        exec 1>/dev/null
        exec 2>/dev/null
    fi

    # Load PostgreSQL & repmgr environment variables
    . /opt/bitnami/scripts/postgresql-env.sh

    postgresql_enable_nss_wrapper

    # Prepare env vars for managing roles
    primary_node="$(repmgr_get_primary_node)"
    primary_host="$(echo $primary_node | awk '{print $1}')"

    # Stop postgresql for graceful exit.
    postgresql_stop

    if [[ "$primary_host" == "$REPMGR_NODE_NETWORK_NAME" ]]; then
        info "Primary node need to wait for a new primary node before leaving the cluster"
        retry_while is_new_primary_ready 10 5
    else
        info "Standby node doesn't need to wait, leaving the cluster."
    fi
---
# Source: holmes-engine-managment/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: dmaapconfig
  namespace: amcop-system
data:
  cfy.json: |
    {
      "services_calls": {},
      "streams_publishes": {
        "dcae_cl_out": {
          "dmaap_info": {
            "topic_url": "http://dmaap.amcop-system.svc.cluster.local:3904/events/unauthenticated.DCAE_CL_OUTPUT"
          },
          "type": "message_router"
        }
      },
      "streams_subscribes": {
        "ves_fault": {
          "dmaap_info": {
            "topic_url": "http://dmaap.amcop-system.svc.cluster.local:3904/events/unauthenticated.SEC_FAULT_OUTPUT"
          },
          "type": "message_router"
        }
      }
    }
  ControlLoop-VOLTE-2179b738-fd36-4843-a71a-a8c24c70c55b.drl: |
    package org.onap.holmes.droolsRule;

    import org.onap.holmes.common.dmaap.DmaapService;
    import org.onap.holmes.common.api.stat.VesAlarm;
    import org.onap.holmes.common.aai.CorrelationUtil;
    import org.onap.holmes.common.dmaap.entity.PolicyMsg;
    import org.onap.holmes.common.utils.SpringContextUtil;
    import org.onap.holmes.common.utils.DroolsLog;

    rule "Relation_analysis_Rule"
    salience 200
    no-loop true
        when
            $root : VesAlarm(alarmIsCleared == 0,
                $sourceId: sourceId, sourceId != null && !sourceId.equals(""),
                $sourceName: sourceName, sourceName != null && !sourceName.equals(""),
                $startEpochMicrosec: startEpochMicrosec,
                eventName in ("Fault_MultiCloud_VMFailure"),
                $eventId: eventId)
            $child : VesAlarm( eventId != $eventId, parentId == null,
                CorrelationUtil.getInstance().isTopologicallyRelated(sourceId, $sourceId, $sourceName),
                eventName in ("Fault_MME_eNodeB out of service alarm"),
                startEpochMicrosec < $startEpochMicrosec + 60000 && startEpochMicrosec > $startEpochMicrosec - 60000)
        then
            DroolsLog.printInfo("===========================================================");
            DroolsLog.printInfo("Relation_analysis_Rule: rootId=" + $root.getEventId() + ", childId=" + $child.getEventId());
            $child.setParentId($root.getEventId());
            update($child);
    end

    rule "root_has_child_handle_Rule"
    salience 150
    no-loop true
        when
            $root : VesAlarm(alarmIsCleared == 0, rootFlag == 0, $eventId: eventId)
            $child : VesAlarm(eventId != $eventId, parentId == $eventId)
        then
            DroolsLog.printInfo("===========================================================");
            DroolsLog.printInfo("root_has_child_handle_Rule: rootId=" + $root.getEventId() + ", childId=" + $child.getEventId());
            DmaapService dmaapService = SpringContextUtil.getBean(DmaapService.class);
            PolicyMsg policyMsg = dmaapService.getPolicyMsg($root, $child, "org.onap.holmes.droolsRule");
            dmaapService.publishPolicyMsg(policyMsg, "dcae_cl_out");
            $root.setRootFlag(1);
            update($root);
    end

    rule "root_no_child_handle_Rule"
    salience 100
    no-loop true
        when
            $root : VesAlarm(alarmIsCleared == 0, rootFlag == 0,
                sourceId != null && !sourceId.equals(""),
                sourceName != null && !sourceName.equals(""),
                eventName in ("Fault_MultiCloud_VMFailure"))
        then
            DroolsLog.printInfo("===========================================================");
            DroolsLog.printInfo("root_no_child_handle_Rule: rootId=" + $root.getEventId());
            DmaapService dmaapService = SpringContextUtil.getBean(DmaapService.class);
            PolicyMsg policyMsg = dmaapService.getPolicyMsg($root, null, "org.onap.holmes.droolsRule");
            dmaapService.publishPolicyMsg(policyMsg, "dcae_cl_out");
            $root.setRootFlag(1);
            update($root);
    end

    rule "root_cleared_handle_Rule"
    salience 100
    no-loop true
        when
            $root : VesAlarm(alarmIsCleared == 1, rootFlag == 1)
        then
            DroolsLog.printInfo("===========================================================");
            DroolsLog.printInfo("root_cleared_handle_Rule: rootId=" + $root.getEventId());
            DmaapService dmaapService = SpringContextUtil.getBean(DmaapService.class);
            PolicyMsg policyMsg = dmaapService.getPolicyMsg($root, null, "org.onap.holmes.droolsRule");
            dmaapService.publishPolicyMsg(policyMsg, "dcae_cl_out");
            retract($root);
    end

    rule "child_handle_Rule"
    salience 100
    no-loop true
        when
            $child : VesAlarm(alarmIsCleared == 1, rootFlag == 0)
        then
            DroolsLog.printInfo("===========================================================");
            DroolsLog.printInfo("child_handle_Rule: childId=" + $child.getEventId());
            retract($child);
    end
  index.json: |
    [
        {
            "closedControlLoopName": "ControlLoop-VOLTE-2179b738-fd36-4843-a71a-a8c24c70c55b",
            "file": "ControlLoop-VOLTE-2179b738-fd36-4843-a71a-a8c24c70c55b.drl"
        }
    ]
---
# Source: holmes-engine-managment/templates/configmap_job.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: dmaapconfigjob
  namespace: amcop-system
data:
  curule: |
    {
      "ruleName": "CG RAN Cellsetup failure",
      "loopControlName": "Cellsetup failure",
      "description": "This rule is designed for the correlation analysis for the Cellsetup failure use case.",
      "content": "package org.onap.holmes.droolsRule1;\nimport java.util.*\nimport org.onap.holmes.engine.db.AlarmInfoDaoService;\nimport org.onap.holmes.common.api.stat.VesAlarm;\nimport org.onap.holmes.common.aai.CorrelationUtil;\nimport org.onap.holmes.common.utils.DroolsLog;\nimport org.onap.holmes.common.utils.SpringContextUtil;\nrule \"Relation_analysis_Rule\"\nsalience 200\nwhen\n$root : VesAlarm(alarmIsCleared == 0,$sourceId: sourceId, sourceId != null && !sourceId.equals(\"\"),$sourceName: sourceName, sourceName != null && !sourceName.equals(\"\"), specificProblem matches (\".*Cell setup failures.*\"),$eventId: eventId)\n$child : VesAlarm(alarmIsCleared == 0,eventId != $eventId, parentId == null,specificProblem matches (\".*F1AP link bounce Alarm.*\"),sourceName == $sourceName)\nthen\nDroolsLog.printInfo(\"Correlation Identified: Root: ID=\" + $root.getEventId() + \", Event Name=\" + $root.getSpecificProblem() +\"; Child: ID=\" + $child.getEventId() + \", Event Name=\" + $child.getSpecificProblem());\n $root.setRootFlag(1);$child.setParentId($root.getEventId());\nupdate($child);update($root)\nAlarmInfoDaoService alarmInfoDaoService = SpringContextUtil.getBean(AlarmInfoDaoService.class);\nalarmInfoDaoService.saveAlarmActive($root);\nalarmInfoDaoService.saveAlarmActive($child);\nend\nrule \"root_has_child_handle_Rule\"\nsalience 100\nwhen\n$child : VesAlarm(alarmIsCleared == 1,specificProblem matches (\".*F1AP link bounce Alarm.*\"))\nthen\nDroolsLog.printInfo(\" Child alarm is cleared: Alarm: ID=\" + $child.getEventId() + \", Event Name=\" + $child.getEventName());\nAlarmInfoDaoService alarmInfoDaoService = SpringContextUtil.getBean(AlarmInfoDaoService.class);alarmInfoDaoService.saveAlarmHistory($child);VesAlarm ves_mv_to_history = alarmInfoDaoService.queryClearedRelatedAlarm($child);alarmInfoDaoService.saveAlarmHistory(ves_mv_to_history);alarmInfoDaoService.deleteAlarmCleared(ves_mv_to_history);\nend\nrule \"root_cleared_handle_Rule\"\nsalience 50\nwhen\n$root : VesAlarm(alarmIsCleared == 1, specificProblem matches (\".*Cell setup failures.*\"))\nthen\nDroolsLog.printInfo(\"Parent alarm is cleared: Alarm: ID=\" + $root.getEventId() + \", Event Name=\" + $root.getEventName());\nAlarmInfoDaoService alarmInfoDaoService = SpringContextUtil.getBean(AlarmInfoDaoService.class);List<VesAlarm> childlist = alarmInfoDaoService.queryAllClearedChildAlarms($root);if(childlist.isEmpty()){alarmInfoDaoService.saveAlarmHistory($root);VesAlarm ves_mv_to_history = alarmInfoDaoService.queryClearedRelatedAlarm($root);alarmInfoDaoService.saveAlarmHistory(ves_mv_to_history);alarmInfoDaoService.deleteAlarmCleared(ves_mv_to_history);}else{System.out.println(\"Parent has child alarms not been cleared, Please check and take corrective action\");}\nend",
      "creator": "self",
      "enabled": 1
    }
---
# Source: holmes-engine-managment/charts/postgress/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgres-headless-svc
  namespace: amcop-system
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: postgresql
      port: 5432
      targetPort: postgresql
      protocol: TCP
  selector:
    app: postgres
---
# Source: holmes-engine-managment/charts/postgress/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgresql
  namespace: amcop-system
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: postgresql
      port: 5432
      targetPort: postgresql
      protocol: TCP
      nodePort: null
  selector:
    app: pgpool
---
# Source: holmes-engine-managment/templates/engine-mngmtsvc.yaml
apiVersion: v1
kind: Service
metadata:
  namespace: amcop-system
  name: holmes
spec:
  type: NodePort
  ports:
    - name: emt
      port: 9102
      targetPort: 9102
    - name: rmt
      port: 9101
      targetPort: 9101
      # - name: postgress
      #   port: 5432
      #   targetPort: 5432
  selector:
    app: holmes
---
# Source: holmes-engine-managment/charts/postgress/templates/pgpool_dep.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pgpool-deployment
  namespace: amcop-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pgpool
  template:
    metadata:
      labels:
        app: pgpool
    spec:
      securityContext:
        fsGroup: 1001
      containers:
        - name: pgpool
          image: docker.io/bitnami/pgpool:4.2.3-debian-10-r38
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: PGPOOL_BACKEND_NODES
              value: 0:postgres-sts-0.postgres-headless-svc:5432,1:postgres-sts-1.postgres-headless-svc:5432,2:postgres-sts-2.postgres-headless-svc:5432
            - name: PGPOOL_SR_CHECK_USER
              value: "repmgr"
            - name: PGPOOL_SR_CHECK_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secrets
                  key: repmgr-password
            - name: PGPOOL_SR_CHECK_DATABASE
              value: "holmes"
            - name: PGPOOL_ENABLE_LDAP
              value: "no"
            - name: PGPOOL_POSTGRES_USERNAME
              value: "holmes"
            - name: PGPOOL_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secrets
                  key: postgresql-password
            - name: PGPOOL_ADMIN_USERNAME
              value: "admin"
            - name: PGPOOL_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: pgpool-secrets
                  key: admin-password
            - name: PGPOOL_ENABLE_LOAD_BALANCING
              value: "yes"
            - name: PGPOOL_ENABLE_LOG_CONNECTIONS
              value: "no"
            - name: PGPOOL_ENABLE_LOG_HOSTNAME
              value: "yes"
            - name: PGPOOL_ENABLE_LOG_PER_NODE_STATEMENT
              value: "no"
            - name: PGPOOL_CHILD_LIFE_TIME
              value: ""
            - name: PGPOOL_ENABLE_TLS
              value: "no"
          ports:
            - name: postgresql
              containerPort: 5432
              protocol: TCP
          livenessProbe:
            exec:
              command:
                - /opt/bitnami/scripts/pgpool/healthcheck.sh
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            exec:
              command:
                - bash
                - -ec
                - PGPASSWORD=${PGPOOL_POSTGRES_PASSWORD} psql -U "holmes" -d "holmes" -h /opt/bitnami/pgpool/tmp -tA -c "SELECT 1" >/dev/null
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
---
# Source: holmes-engine-managment/templates/engine-mngmt.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: holmes
  namespace: amcop-system
  labels:
    app: holmes
spec:
  replicas: 1
  selector:
    matchLabels:
      app: holmes
  template:
    metadata:
      labels:
        app: holmes
    spec:
      initContainers:
        - name: wait-for-svc-before-starup
          # image: postgres:9.5
          image: busybox
          command: ["sh", "-c", "until timeout 1 nc -z postgresql 5432 > /dev/null; do echo Waiting for master.; sleep 30; done"]
          # command: ["pg_isready", "-h", " postgresql", "-p", "5432", "-U", "postgresql"]
      containers:
        - name: emt
          image: amcop/holmes-engine-management:v3.5.01122024
          imagePullPolicy: IfNotPresent
          env:
            - name: URL_JDBC
              value: "postgresql"
            - name: MSB_ADDR
              value: "127.0.0.1"
            - name: HOST_IP
              value: "127.0.0.1"
            - name: MSB_IAG_SERVICE_HOST
              value: "127.0.0.1"
            - name: MSB_IAG_SERVICE_PORT
              value: "10081"
            - name: ENABLE_ENCRYPT
              value: "false"
          volumeMounts:
            - mountPath: /opt/hemtopics
              name: dmaapvol
        - name: rmt
          image: amcop/holmes-rule-management:v3.5.01122024
          imagePullPolicy: IfNotPresent
          env:
            - name: URL_JDBC
              value: "postgresql"
            - name: MSB_ADDR
              value: "127.0.0.1"
            - name: HOST_IP
              value: "127.0.0.1"
            - name: MSB_IAG_SERVICE_HOST
              value: "127.0.0.1"
            - name: MSB_IAG_SERVICE_PORT
              value: "10081"
            - name: ENABLE_ENCRYPT
              value: "false"
          volumeMounts:
            - mountPath: /opt/hemtopics
              name: dmaapvol
              # - mountPath: /opt/hrmrules/
              #   name: dmaapvol
      volumes:
        - name: dmaapvol
          configMap:
            name: dmaapconfig
---
# Source: holmes-engine-managment/charts/postgress/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-sts
  namespace: amcop-system
spec:
  serviceName: postgres-headless-svc
  replicas: 3
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      securityContext:
        fsGroup: 1001
      containers:
        - name: postgresql
          lifecycle:
            preStop:
              exec:
                command:
                  - /pre-stop.sh
          image: docker.io/bitnami/postgresql-repmgr:9.6.24-debian-10-r72
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          # Auxiliary vars to populate environment variables
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            # PostgreSQL configuration
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_USER
              value: "holmes"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secrets
                  key: postgresql-password
            - name: POSTGRES_DB
              value: "holmes"
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "true"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit, repmgr"
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Repmgr configuration
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: REPMGR_UPGRADE_EXTENSION
              value: "no"
            - name: REPMGR_PGHBA_TRUST_ALL
              value: "no"
            - name: REPMGR_MOUNTED_CONF_DIR
              value: "/bitnami/repmgr/conf"
            - name: REPMGR_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: REPMGR_PARTNER_NODES
              value: postgres-sts-0.postgres-headless-svc.$(REPMGR_NAMESPACE).svc.cluster.local,postgres-sts-1.postgres-headless-svc.$(REPMGR_NAMESPACE).svc.cluster.local,postgres-sts-2.postgres-headless-svc.$(REPMGR_NAMESPACE).svc.cluster.local
            - name: REPMGR_PRIMARY_HOST
              value: "postgres-sts-0.postgres-headless-svc.$(REPMGR_NAMESPACE).svc.cluster.local"
            - name: REPMGR_NODE_NAME
              value: "$(MY_POD_NAME)"
            - name: REPMGR_NODE_NETWORK_NAME
              value: "$(MY_POD_NAME).postgres-headless-svc.$(REPMGR_NAMESPACE).svc.cluster.local"
            - name: REPMGR_LOG_LEVEL
              value: "NOTICE"
            - name: REPMGR_CONNECT_TIMEOUT
              value: "5"
            - name: REPMGR_RECONNECT_ATTEMPTS
              value: "3"
            - name: REPMGR_RECONNECT_INTERVAL
              value: "5"
            - name: REPMGR_USERNAME
              value: "repmgr"
            - name: REPMGR_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secrets
                  key: repmgr-password
            - name: REPMGR_DATABASE
              value: "repmgr"
          ports:
            - name: postgresql
              containerPort: 5432
              protocol: TCP
          livenessProbe:
            exec:
              command:
                - bash
                - -ec
                - 'PGPASSWORD=$POSTGRES_PASSWORD psql -w -U "holmes" -d "holmes"  -h 127.0.0.1 -c "SELECT 1"'
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - bash
                - -ec
                - 'PGPASSWORD=$POSTGRES_PASSWORD psql -w -U "holmes" -d "holmes"  -h 127.0.0.1 -c "SELECT 1"'
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: data
              mountPath: /bitnami/postgresql
            - name: hooks-scripts
              mountPath: /pre-stop.sh
              subPath: pre-stop.sh
      volumes:
        - name: hooks-scripts
          configMap:
            name: postgres-configmap
            defaultMode: 0755
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "2Gi"
        storageClassName: amcop-local-path
---
# Source: holmes-engine-managment/templates/job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "holmes-engine-managment"
  namespace: amcop-system
  labels:
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "holmes-engine-managment"
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": post-install
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  backoffLimit: 2
  template:
    metadata:
      name: "holmes-engine-managment"
      labels:
        app.kubernetes.io/managed-by: "Helm"
        app.kubernetes.io/instance: "holmes-engine-managment"
    spec:
      restartPolicy: Never
      containers:
        - name: post-install-job
          image: amcop/holmes-engine-management:v3.5.01122024
          command:
            - "/bin/bash"
            - "-ec"
            - "for i in {1..5}; do sleep 60 && curl -v -X PUT -H 'Content-Type: application/json'  -d @/opt/hemtopics/curule  holmes.amcop-system.svc.cluster.local:9101/api/holmes-rule-mgmt/v1/rule || break; done"
            # - "#!/bin/sh"
          # - " sleep 60 && "
          volumeMounts:
            - mountPath: /opt/hemtopics
              name: dmaapvol
              # - mountPath: /opt/hrmrules/
              #   name: dmaapvol
      volumes:
        - name: dmaapvol
          configMap:
            name: dmaapconfigjob
---
# Source: rule-adapter-helm/templates/deployment.yaml
volumeClaimTemplates:
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ruleadapter-pvc
  namespace: amcop-system
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Mi
  storageClassName: amcop-local-path
  volumeMode: Filesystem
---
# Source: rule-adapter-helm/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: rule-adapter-helm
  namespace: amcop-system
  labels:
    app.kubernetes.io/name: rule-adapter-helm
    app.kubernetes.io/instance: rule-adapter-helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
      # nodePort:
  selector:
    app.kubernetes.io/name: rule-adapter-helm
    app.kubernetes.io/instance: rule-adapter-helm
---
# Source: rule-adapter-helm/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rule-adapter-helm
  namespace: amcop-system
  labels:
    app.kubernetes.io/name: rule-adapter-helm
    app.kubernetes.io/instance: rule-adapter-helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: rule-adapter-helm
      app.kubernetes.io/instance: rule-adapter-helm
  template:
    metadata:
      labels:
        app.kubernetes.io/name: rule-adapter-helm
        app.kubernetes.io/instance: rule-adapter-helm
    spec:
      volumes:
        - name: ruleadapter-pvc
          persistentVolumeClaim:
            claimName: ruleadapter-pvc
      containers:
        - name: rule-adapter-helm
          image: "amcop/rule-adapter:v3.5.01122024"
          imagePullPolicy: IfNotPresent
          env:
            - name: "SMO_URL"
              value: "sdnr.amcop-system.svc.cluster.local"
            - name: "PORT"
              value: "8080"
            - name: "SDNR_PORT"
              value: "8181"
            - name: "SDNR_USERNAME"
              value: "admin"
            - name: "SDNR_PASS"
              value: "Kp8bJ4SXszM0WXlhak3eHlcse2gAw84vaoGGmJvUy2U"
            - name: "sdnr_ip"
              value: "sdnr.amcop-system.svc.cluster.local"
            - name: "RULEPATH"
              value: "/data/rules.json"
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          volumeMounts:
            - mountPath: "/data"
              name: ruleadapter-pvc
              ################################[ SMO UI ]################################
################################[ SMO UI ]################################
---
# Source: smo-ui/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: smo-ui
  namespace: amcop-system
  labels:
    app.kubernetes.io/name: smo-ui
    app.kubernetes.io/instance: smo-ui
spec:
  type: NodePort
  ports:
    - port: 3000
      nodePort: 31065
      name: http
  selector:
    app.kubernetes.io/name: smo-ui
    app.kubernetes.io/instance: smo-ui
---
# Source: smo-ui/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: smo-ui
  namespace: amcop-system
  labels:
    app.kubernetes.io/name: smo-ui
    app.kubernetes.io/instance: smo-ui
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: smo-ui
      app.kubernetes.io/instance: smo-ui
  template:
    metadata:
      labels:
        app.kubernetes.io/name: smo-ui
        app.kubernetes.io/instance: smo-ui
    spec:
      containers:
        - name: smo-ui
          image: "amcop/smo-ui:v3.5.01122024"
          imagePullPolicy: IfNotPresent
          env:
            - name: "REACT_APP_CORRELATED_URL"
              value: "http://fault-management-helm.amcop-system.svc.cluster.local"
            - name: "REACT_APP_CORRELATED_PORT"
              value: "9797"
            - name: "REACT_APP_ALARMLOGS_URL"
              value: "http://fault-management-helm.amcop-system.svc.cluster.local"
            - name: "REACT_APP_ALARMLOGS_PORT"
              value: "9797"
            - name: "REACT_APP_VIEW_RULE_API"
              value: "http://fault-management-helm.amcop-system.svc.cluster.local:9797/viewrules"
            - name: "REACT_APP_EDIT_RULE_API"
              value: "http://fault-management-helm.amcop-system.svc.cluster.local:9797/editrule"
            - name: "REACT_APP_ALARMS_COUNT_PORT"
              value: "9797"
            - name: "REACT_APP_ALARMS_COUNT_URL"
              value: "http://fault-management-helm.amcop-system.svc.cluster.local"
            - name: "REACT_APP_VERIFY_TOKEN_URL"
              value: "http://fault-management-helm.amcop-system.svc.cluster.local"
            - name: "REACT_APP_VERIFY_TOKEN_PORT"
              value: "9797"
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: "REACT_APP_FAULT_PROVIDER_URL"
              value: "http://fault-management-helm.amcop-system.svc.cluster.local:9797"
            - name: "REACT_APP_RULE_ADAPTER_URL"
              value: "http://rule-adapter-helm.amcop-system.svc.cluster.local:8080"
            - name: "REACT_APP_SDNR_URL"
              value: "http://sdnr.amcop-system.svc.cluster.local:8181"
            - name: "REACT_APP_LOGIN_REDIRECT_URL"
              value: "http://$(HOST_IP):30181/odlux/index.html"
          ports:
            - name: http
              containerPort: 3000
          resources: {}
